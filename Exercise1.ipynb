{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample the point clouds\n",
    "source_down = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target_down = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "# Estimate normals of downsampled point clouds\n",
    "source_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "    radius=voxel_size*2, max_nn=30))\n",
    "target_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
    "    radius=voxel_size*2, max_nn=30))\n",
    "\n",
    "# Compute FPFH features for downsampled point clouds\n",
    "source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    source_down, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*5, max_nn=100))\n",
    "target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    target_down, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*5, max_nn=100))\n",
    "# Global registration with RANSAC\n",
    "We are going to use [open3d](http://www.open3d.org/) to handle point clouds and generation of point clouds\n",
    "We are importing the packages and defining a function which helps us drawing the point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing\n",
    "# If you want it to be more clear set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in our pointclouds. For that we use the `io` module of the\n",
    "open3d package (`o3d`). The following cell will open a window with a\n",
    "visualization of both point clouds `source` and `target`.\n",
    "\n",
    "Also, this page [Visualization - Open3D](http://open3d.org/html/tutorial/Basic/visualization.html)\n",
    "contains some useful examples and instructions on how to use the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"ICP/r2.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "# Show models side by side\n",
    "draw_registrations(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding features in pointclouds\n",
    "When working on point clouds it can be beneficial to work on a downsampled version of the point cloud,\n",
    "as it decreases the need of computation.\n",
    "\n",
    "You can use [`pointcloud.voxel_down_sample()`](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html#open3d.geometry.PointCloud.voxel_down_sample) where `pointcloud` is the name of your point cloud object. In our case, that would be `source` and `target`.\n",
    "\n",
    "We also need to estimate the normals of the point cloud points using [`pointcloud.estimate_normals()`](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html#open3d.geometry.PointCloud.voxel_down_sample)\n",
    "\n",
    "**Task:** Find FPFH features or correspondances of the downsampled point clouds.\n",
    "[`o3d.pipelines.registration.compute_fpfh_feature()`](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.compute_fpfh_feature.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "\n",
    "# # Code\n",
    "source_down = source.voxel_down_sample(voxel_size=0.05)\n",
    "target_down = target.voxel_down_sample(voxel_size=0.05)\n",
    "# draw_registrations(source_down, target_down)\n",
    "#\n",
    "source_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "target_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "#\n",
    "source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(source_down, o3d.geometry.KDTreeSearchParamHybrid(radius=0.25, max_nn=100))\n",
    "target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(target_down, o3d.geometry.KDTreeSearchParamHybrid(radius=0.25, max_nn=100))\n",
    "#\n",
    "#correspondences = o3d.pipelines.registration.correspondence_feature_based(source_fpfh, target_fpfh, mutual_filter=True)\n",
    "draw_registrations(source_down, target_down)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANSAC \n",
    "We will now attempt to use RANSAC to do a global registration of the two point clouds.\n",
    "\n",
    "By using the function [`o3d.pipelines.registration.registration_ransac_based_on_feature_matching`](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.registration_ransac_based_on_feature_matching.html) from open3d, do the following:\n",
    "\n",
    "\n",
    "Try to find the transformation from `r1.pcd` (`source`) to `r2.pcd` (`target`).\n",
    "Attempt with point-to-point and point-to-plane\n",
    "```Python\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "```\n",
    "\n",
    "When using RANSAC, focus on the arguments below. The rest are optional parameters.\n",
    "```Python\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.53489662  0.84475731  0.0164525   0.58954274]\n",
      " [-0.2374326  -0.16897194  0.95659513  0.91449413]\n",
      " [ 0.81087075  0.50777314  0.29095544 -1.50147516]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Set the RANSAC parameters\n",
    "\n",
    "point_to_point = o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "# Set the distance threshold for RANSAC\n",
    "distance_threshold = 0.075\n",
    "\n",
    "# Perform RANSAC-based registration using point-to-point method\n",
    "ransac_result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_down, target_down, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "\n",
    "# Get the transformation matrix\n",
    "transformation_matrix = ransac_result.transformation\n",
    "\n",
    "# Print the transformation matrix\n",
    "print(transformation_matrix)\n",
    "\n",
    "# Apply the transformation to the source point cloud\n",
    "source_transformed = source_down.transform(transformation_matrix)\n",
    "\n",
    "# Visualize the registration result\n",
    "draw_registrations(source_transformed, target_down)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercises\n",
    "### A)\n",
    "Can you get a decent transformation from r1 to r3? (check the ICP folder)\n",
    "### B)\n",
    "With the following checkers, can you get better results from RANSAC? Try tweaking the parameters of them. Can you make point-to-plane work? Do not spend too much time on this, if you can't manage, skip it. (I was not able to get a good fit.)\n",
    "\n",
    "\n",
    "You can also try tweaking the `voxel_size`\n",
    "\n",
    "```Python\n",
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "checker_list = [c0,c1,c2]\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23227502  0.95713942 -0.17300995  0.33002872]\n",
      " [ 0.26850882  0.23406178  0.93440789 -0.41665994]\n",
      " [ 0.93485364  0.17058491 -0.31136708  0.07577581]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "# Read in the point clouds\n",
    "source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"ICP/r3.pcd\")\n",
    "\n",
    "# Downsample the point clouds\n",
    "voxel_size = 0.05\n",
    "source_down = source.voxel_down_sample(voxel_size)\n",
    "target_down = target.voxel_down_sample(voxel_size)\n",
    "\n",
    "# Estimate the normals of the downsampled point clouds\n",
    "source_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "target_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Compute FPFH features\n",
    "source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(source_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=0.25, max_nn=100))\n",
    "target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(target_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=0.25, max_nn=100))\n",
    "\n",
    "# Set the RANSAC parameters\n",
    "distance_threshold = voxel_size * 1.5\n",
    "point_to_point = o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "# Perform RANSAC-based global registration\n",
    "ransac_result_p2p = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_down, target_down, source_fpfh, target_fpfh,True,\n",
    "    distance_threshold, point_to_point)\n",
    "\n",
    "# Print the transformation matrix\n",
    "print(ransac_result_p2p.transformation)\n",
    "\n",
    "# Apply the transformation to the source point cloud\n",
    "source_transformed = source_down.transform(ransac_result_p2p.transformation)\n",
    "\n",
    "# Visualize the registration result\n",
    "draw_registrations(source_transformed, target_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99845899 -0.05487709  0.00825535  0.07861426]\n",
      " [ 0.05541871  0.99377485 -0.09664533  0.02448248]\n",
      " [-0.00290035  0.0969539   0.99528465 -0.17741354]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#B\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "#\n",
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "checker_list = [c0,c1,c2]\n",
    "\n",
    "ransac_result_b = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_down, target_down, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)\n",
    "checker_list\n",
    "transformation_matrix = ransac_result_b.transformation\n",
    "print(transformation_matrix)\n",
    "\n",
    "# Apply the transformation to the source point cloud\n",
    "source_transformed = source_down.transform(transformation_matrix)\n",
    "\n",
    "# Visualize the registration result\n",
    "draw_registrations(source_transformed, target_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd5a613775d973e3ebb98e1e77334e79b1df328fc590baa0c4f920a9a4d0a201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
